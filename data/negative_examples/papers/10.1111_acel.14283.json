{
  "doi": "10.1111/acel.14283",
  "title": "Epistemic uncertainty challenges aging clock reliability in predicting rejuvenation effects",
  "abstract": "Epigenetic aging clocks have been widely used to validate rejuvenation effects during cellular reprogramming. However, these predictions are unverifiable because the true biological age of reprogrammed cells remains unknown. We present an analytical framework to consider rejuvenation predictions from the uncertainty perspective. Our analysis reveals that the DNA methylation profiles across reprogramming are poorly represented in the aging data used to train clock models, thus introducing high epistemic uncertainty in age estimations. Moreover, predictions of different published clocks are inconsistent, with some even suggesting zero or negative rejuvenation. While not questioning the possibility of age reversal, we show that the high clock uncertainty challenges the reliability of rejuvenation effects observed during in vitro reprogramming before pluripotency and throughout embryogenesis. Conversely, our method reveals a significant age increase after in vivo reprogramming. We recommend including uncertainty estimation in future aging clock models to avoid the risk of misinterpreting the results of biological age prediction.",
  "full_text": {
    "INTRODUCTION": "Reprogramming aged somatic cells into pluripotency or other progenitor states was consistently shown to ameliorate various aging‐associated features, either by applying different transcription factors (TFs) or by introducing small molecules to cells in vitro or in vivo (Browder et al., 2022; Chondronasiou et al., 2022; Gill et al., 2022; Olova et al., 2019; Yang et al., 2023). To quantify the effect of age reversal, researchers resort to various methods, including “epigenetic aging clock” models built from DNA methylation (DNAm) data with diverse machine learning (ML) approaches. These approaches are widely employed to compare the “biological age” of reprogrammed cells to that of control cells (Simpson et al., 2021) (Figure 1a,b). These clocks are easy to use and can assess aging from the organismal to the cellular levels, which is particularly valuable in experiments where the large‐scale parameters of organismal aging cannot be measured, such as in vitro cellular reprogramming. Notably, a similar approach has recently been used to demonstrate rejuvenation in the course of embryonic development (Kerepesi et al., 2021; Kerepesi & Gladyshev, 2023; Trapp et al., 2021).\n\nThe primary assumption of aging clocks is that the deviation ∆ of predicted age from the chronological age C represents an accelerated or decelerated aging, that is, an increase or decrease in the biological age B (Rutledge et al., 2022; Sluiskes et al., 2024). One can express it as B = C + ∆. Since biological age cannot be measured directly (i.e., it lacks a definitive “ground truth”), the epigenetic age estimated by the clocks is therefore considered a proxy measure of the biological age (Yousefi et al., 2022). Consequently, owing to the fact that DNAm patterns are strong indicators of past influences and future health outcomes, the epigenetic age is proposed to serve as a biomarker for measuring the effects of pro‐longevity interventions in clinical trials (Mitteldorf, 2019; Rutledge et al., 2022; Zhavoronkov et al., 2019).\n\nHowever, before aging clocks could be integrated into clinical practice, these models should provide an estimate of uncertainty for their own predictions. Uncertainty manifests itself in three ways (Chua et al., 2023; Hüllermeier & Waegeman, 2021): (i) Model choice uncertainty, part of a broader category known as epistemic uncertainty, represents how well a proposed model (its architecture, parameters, metrics, etc.) reflects the actual underlying process (Figure 1c). (ii) Out‐of‐distribution (OOD) uncertainty, another type of epistemic uncertainty, emerges when the testing data are not represented in the training data distribution, leading to a high risk of model prediction failure (Figure 1d). (iii) Aleatoric uncertainty originates from data variations that cannot be reduced to zero by the model (e.g., when the same DNAm level corresponds to different ages) (Figure 1e).\n\nDataset shift (Quinonero‐Candela et al., 2008) term describes the case of OOD sampling where the testing population is under‐represented within the training distribution. Dataset shift can be decomposed into covariate shift (e.g., differently distributed DNAm values) and response shift (e.g., different age ranges). Notably, batch effect serves as a notorious example of dataset shift in the field of omics data analysis because it indicates differences in covariate or response distributions between sample groups.\n\nFrom the clinical perspective, epistemic uncertainty must be estimated to make reliable conclusions about whether to trust a model or not (Chua et al., 2023). Specifically, epistemic uncertainty resulting from the dataset shift should be scrutinized, considering the prevalence of batch effects in biological data (Adamer et al., 2022; Zindler et al., 2020). However, most popular DNAm aging clocks fail to meet this criterion (Figure 1f) because they are typically built using algorithms from the penalized multivariate linear regression (MLR) family (Mei et al., 2023) (e.g., ElasticNet). Such algorithms do not yield information on any of the uncertainties, except for the error between chronological and predicted ages in the training data (e.g., mean or median absolute errors, MAE or MedAE).\n\nIn this work, we question the applicability of existing aging clock methodology for measuring rejuvenation by specifically examining prediction uncertainty (Figure 1). To achieve this, we reanalyze published data of putative rejuvenation, focusing on extreme cases of anticipated dataset shift, such as cellular reprogramming and embryonic development.\n\nBecause biological age measurements cannot be verified explicitly, we introduce four different indirect approaches to this problem: (i) Elucidating covariate shift in DNAm values between the datasets of aging and rejuvenation. (ii) Evaluating the agreement between different aging clocks in predicting rejuvenation. (iii) Exploring if rejuvenation datasets can be employed reciprocally to predict normal aging. (iv) Assessing whether an aging clock capable of estimating its own uncertainty (Figure 1g) would demonstrate a significant age reversal in putative rejuvenation experiments.\n\nWe propose a comprehensive framework for implementing these approaches. By leveraging this framework, we aim to elucidate the most critical limitations in applying aging clock models to rejuvenation studies, which should be solved in order to drive broader acceptance of these models within the longevity community.\n\n",
    "RESULTS - Covariate shift can lead to biologically meaningless predictions": "To introduce the concept of covariate shift in the field of aging clocks, we first explored a simple, low‐dimensional example. In particular, we used two parameters (biomarkers) to construct an elementary aging clock for predicting chronological age in humans: weight and height (Figure 2a; see Methods). These two biomarkers strongly correlate with age during the first 20 years of human life (World Health Organization et al., 2006), therefore they can legitimately be used for age prediction. We analyzed the data of body measurements for male humans ranging from 1 to 25 years old (an approximate end of body growth), including both healthy controls (World Health Organization et al., 2006) and individuals with the achondroplasia disorder (Hoover‐Fong et al., 2021; Hunter et al., 1996) typically characterized by a shorter length of arms and legs (Pauli, 2019).\n\nInspired by the common framework of aging clocks construction established in earlier works (Hannum et al., 2013; Hollingsworth et al., 1965; Horvath, 2013), we trained an MLR model using body measurements of a cohort of healthy individuals to predict their chronological age, which yielded a good performance on the training data (MAE = 2.3 years, R\n2 = 0.84). For the achondroplasia cohort, these clocks predicted consistently lower ages (Figure 2b), which would be viewed as decelerated aging in the context of other aging clocks. However, this interpretation has no biological support because the average lifespan of people with achondroplasia is around 10 years shorter than that of control individuals due to early‐life mortality (Pauli, 2019). We assume that this underestimation of ages in the achondroplasia cohort is caused by a covariate shift in the analyzed data, leading to a huge OOD uncertainty, which is not taken into account by the model. Indeed, the distributions of covariates (weight and height) differs significantly between the training and the testing data (Kolmogorov–Smirnov (KS) test, p value <0.0003; Figure 2a). In general, any significant differences between the observed distributions in training and testing samples should caution us against the casual application of ML models.\n\nNext, we expanded our analysis beyond this simplistic case to examine various DNAm datasets and to thoroughly investigate possible covariate shifts in the context of epigenetic aging clocks.\n\n",
    "RESULTS - Reprogramming and embryogenesis datasets exhibit significant covariate shifts relative to aging datasets": "Covariate shifts can arise from various intrinsic and technical factors, including differences in sampling sources and locations, tissue cell content, sample handling techniques, instrumental effects, etc. (Zindler et al., 2020). To estimate the extent of covariate shift in DNAm studies, we analyzed four representative scenarios in the order of increasing expected difference between the distributions of DNAm patterns: (i) One aging dataset split into two subsets; (ii) Two independent aging datasets; (iii) Aging vs. cellular reprogramming in vitro and in vivo; and (iv) Aging vs. early embryogenesis, for which epigenetic rejuvenation was also demonstrated (Kerepesi et al., 2021).\n\nAs our study was aimed at testing the analytical framework rather than at providing comprehensive coverage of dataset shift in all existing data of putative rejuvenation, we focused on several outstanding cases of reprogramming, where DNAm was profiled across as many time points as possible, and the datasets were published in open access (see Methods).\n\nFirst, we examined a DNAm dataset of aging human skin by Roos et al. (2017) split randomly into the training and testing subsets. As anticipated, we detected no discernible covariate shift: the subsets are indistinguishable by the PCA (Figure 2c), DNAm value distributions of at least top‐4 age‐correlated CpGs from both subsets perfectly overlay each other (Figure 2d), and the KS test for distribution similarity further confirms the lack of covariate shift (Figure 2e).\n\nSecond, for two independent datasets of aging human skin (Roos et al., 2017; Vandiver et al., 2015), moderate covariate shift is evident from a similar analysis (Figure 2f,g), with the KS test indicating substantial differences in individual distributions (Figure 2h): 81% percent of sites were rejected by the test (meaning that these CpGs have different distributions). On the other hand, a joint analysis of two aging mouse liver datasets (Meer et al., 2018; Thompson et al., 2018) displays minimal covariate shift (only 1% of CpGs are rejected) (Extended Data Figure 1d‐f).\n\nThird, a comparison of the aging human skin dataset (Roos et al., 2017) with two datasets of in vitro human fibroblast reprogramming (Gill et al., 2022; Ohnuki et al., 2014) revealed strong covariate shifts: at the early stages, the fibroblasts appear to closely resemble aging skin samples in their principal component (PC) coordinates (Figure 2i; Extended Data Figure 1a), but, as the reprogramming progresses through the maturation phase, a notable departure from the aging skin samples can be observed (86% and 69% of CpGs are rejected, respectively; Figure 2j,k; Extended Data Figure 1b,c). Such sample behavior during in vitro reprogramming might suggest that the reprogrammed cells acquire some phenotype unobservable in vivo.\n\nTo shed more light on this hypothesis, we further compared a dataset of in vivo reprogramming in mouse liver (Chondronasiou et al., 2022) with merged liver samples from two datasets of mouse aging (Meer et al., 2018; Thompson et al., 2018), as these two studies demonstrated no significant difference in the previous analysis. As a result, we detected a moderate covariate shift according to the PCA and the KS test (32% of CpGs were rejected, Extended Data Figure 1g‐i), which might imply that the in vivo conditions are better at preserving the normal phenotypic characteristics.\n\nFourth, to address the “ground zero” hypothesis of epigenetic rejuvenation during embryogenesis (Gladyshev, 2021), we compared mouse embryos (Auclair et al., 2014) with blood aging samples (Thompson et al., 2018), as both of these datasets were used previously to demonstrate this phenomenon (Kerepesi et al., 2021). The first stages of embryogenesis strongly diverge from the aging samples, while the later stages align closer to the aging cluster on PCA, suggesting a moderate covariate shift, which is further supported by the KS test (15% of CpGs were rejected, Extended Data Figure 1j‐l).\n\nThese results collectively suggest that the DNAm covariates can lead to significant shifts between datasets, thereby implicitly increasing the risk of clock prediction failure. Given these risks, we advocate for the routine checks of covariate shifts between datasets using the combination of PCA and KS test or other techniques reviewed elsewhere (Quinonero‐Candela et al., 2008) before applying aging clocks.\n\n",
    "RESULTS - Aging clocks are inconsistent in their predictions for reprogramming‐induced rejuvenation": "When choosing a specific ML model to construct an aging clock, a researcher inevitably introduces model uncertainty (Figure 3a). The choice of model family (e.g., Linear Regression) includes certain assumptions about how the true process of epigenetic aging, not accessible a priori, works. Therefore, by training different aging clocks on different data or using different ML model families, one can expect to obtain varying clock CpG subsets (Galkin et al., 2020) and poorly consistent predictions of normal aging (Liu et al., 2020).\n\nTo demonstrate a critical role of model uncertainty, we leveraged eight published aging clocks trained on different CpG sets and tissue types (Hannum et al., 2013; Horvath, 2013; Horvath et al., 2018; Levine et al., 2018; McEwen et al., 2020; Wu et al., 2019; Zhang et al., 2019) and applied them to two in vitro reprogramming datasets (see Methods). As expected, all these clocks varied greatly in their predictions across the reprogramming timeline (Figure 3b, Extended Data Figure 2a). We further focused on the period of the first 3 weeks of reprogramming (from initiation to maturation), as the end of the third week (approximately, day 20) marks the loss of somatic identity and the increasing risk of teratoma formation (Olova et al., 2019), which is undesirable from the clinical standpoint. A comparison of differences between the ages estimated at the beginning and at the last available time point before the end of this period (that is, day 15 for Ohnuki et al. (2014) and day 17 for Gill et al. (2022) exhibits evident inconsistencies for both datasets, ranging from the Horvath multi‐tissue clock (Horvath, 2013) predicting age reversal by 40 years to the Hannum blood clock (Hannum et al., 2013) predicting age increase by 13 years (Figure 3c and Extended Data Figure 2a,b).\n\nTo test the hypothesis that these discrepancies might have arisen from the differences in training datasets rather than from the clock models themselves (most of which are based on ElasticNet regression), we trained different ML models on the same dataset of aging human skin (Roos et al., 2017) and discovered that their predictions of rejuvenation demonstrate a considerable instability as well (Figure 3d, Extended Data Figure 2c). Despite these inconsistencies, most models indicated epigenetic age reversal. Therefore, the clocks could potentially serve as qualitative (or binary) predictors of rejuvenation for the in vivo studies.\n\nTo explore this possibility, we estimated biological ages in the in vivo reprogramming dataset (Chondronasiou et al., 2022). For that, we developed new aging clocks by fitting a Lasso regression over the combined dataset of aging mouse liver (Meer et al., 2018; Thompson et al., 2018) (see Methods) considering that the CpGs in these aging and reprogramming datasets poorly overlap with the existing clock models, thus impeding their use. Our Lasso clocks yielded quite robust performance (Figure 3e), but they failed to register significant rejuvenation in old mice treated with OSKM factors (at the 0.05 level of significance), compared to old control mice (Figure 3f). Notably, all models consistently predicted higher ages for all control liver samples, suggesting a response shift (Quinonero‐Candela et al., 2008) (i.e., PtrainY≠PtestY) between the training and testing datasets, which might result from the differences in DNAm patterns between the training and testing mouse strains (inbred C57BL/6 and transgenic i4F‐B, respectively).\n\nTaken together, our findings highlight a considerable instability of predictions with regard to the choice of both the training dataset and the model family employed for prediction. This lack of agreement between the aging clocks could, supposedly, result from the covariate and the response shifts described previously in this study, as well as from the manifestation of model uncertainty, leading to the divergent rejuvenation dynamics.\n\n",
    "RESULTS - Reprogramming data cannot be used to predict normal aging": "We further examined the interchangeability of the aging and reprogramming datasets. When the regression models are trained, they need to satisfy a certain degree of correlation expressed, for example, as the R\n2 score or mean absolute error (MAE). Supposedly, in an ideal case, when a clock predicts age with absolute accuracy (R\n2 = 1.0, MAE = 0), the predicted ages can be used interchangeably with the true chronological ages (because they are equal) to train another model on the testing data, and to predict ages in the original training dataset with the same accuracy. In reality, this ideal case is never observed due to the technical and biological variations in the training and testing samples and sampling techniques, and due to model under‐ or overfitting. But we hypothesize that if these effects are small (i.e., if there is little epistemic uncertainty), then the reciprocal prediction of training data by the ages predicted for testing data should still be possible, albeit with some degree of error.\n\nTo evaluate this mutual interchangeability of datasets from the perspective of model training, we developed an Inverse Train‐Test Procedure (ITTP, see Methods) (Figure 4a,b). Considering the availability of ground truth measurements, we divided the ITTP use cases into two categories. In case 1, when comparing two aging datasets, the biological ages are available for the testing dataset Xte and Yte (Figure 4a) because they can be approximated by the chronological ages due to the fact that the chronological ages provide important information on the biological ones (Klemera & Doubal, 2006). According to the ITTP, we first train model 1 (e.g., a linear regression) on the training set Xtr and Ytr to predict the ages of testing samples Y^te, where the hat symbol  denotes predicted values. Second, model 2 is trained using the testing features Xte and the ages predicted by the model 1 Y^te. If the datasets are indeed interchangeable, similarly good performance metrics are expected for the predictions made by model 2 for the original training samples (Figure 4a).\n\nIn case 2, when leveraging an aging DNAm dataset { Xtr, Ytr} and a reprogramming dataset { Xrep}, we cannot approximate biological ages for the testing dataset (Figure 4b) because we do not expect the biological age of reprogrammed cells to stay approximately the same as their chronological age, as would be the case for a dataset of normal aging. As before, we train model 1 on the training data and predict the ages of reprogramming samples Y^rep. In this scenario, we cannot validate our predictions due to the lack of ground truth values of biological age for reprogrammed cells, so we can only assume that the predictions are correct and use them to train model 2. If, as a result, we observe good performance metrics between the model 2 predictions and the ages of the original training dataset, then we can still assume interchangeability, regardless of the intermediary predictions of model 1. On the other hand, if we obtain poor prediction accuracy for model 2, then we infer that these datasets are not interchangeable, and that such prediction failure was supposedly caused by a large epistemic uncertainty, presumably originated from a substantial dataset shift. In summary, the ITTP approach contributes to our multifaceted estimation of prediction uncertainty in aging and reprogramming.\n\nWe further applied this procedure to all pairs of datasets described previously (Figure 2 and Extended Data Figure 1) and used the Lasso regression model family as models 1 and 2 (see Methods). Models performed well for the aging human skin dataset (Roos et al., 2017) (Figure 4c,d), both when applying model 1 to predict testing data ages (Pearson's r = 0.934, MAE = 2.8 years) and when applying model 2 to predict ages of the original training data (Pearson's r = 0.831, MAE = 4.4 years) using Y^te instead of Yte to fit model 2. Therefore, we inferred that the training and the testing datasets are interchangeable and can be used reciprocally to predict each other, which is expected for a dataset split randomly into two parts. Similarly, we obtained good reciprocal predictions for the mouse blood samples subset (Thompson et al., 2018) (Extended Data Figure 3e).\n\nIn accordance with the already demonstrated evidence that the datasets of aging mouse liver (Meer et al., 2018; Thompson et al., 2018) exhibit no significant covariate shift (Extended Data Figure 1d), we observed that they both pass the ITTP relatively well (Extended Data Figure 3b,c). A slightly lower accuracy of predicting Meer ages with clocks trained on Thompson data (Pearson's r = 0.737, MAE = 6.14 months) might be attributed to the presence of a number of outliers in the Meer dataset (Extended Data Figure 1d). At the second step, however, we obtained great performance metrics (Pearson's r = 0.975, MAE = 1.49 months), which is another evidence of absence of a significant covariate shift between these datasets.\n\nCase 2 applications of the ITTP demonstrated more diverse results. Both in vitro fibroblast reprogramming datasets (Figure 4e and Extended Data Figure 3a) yielded poor predictions for the aging human skin data (Pearson's r = 0.235, MAE = 52.7 years and Pearson's r = 0.239, MAE = 34.3 years for the second‐step models trained on the Ohnuki et al. (2014) and the Gill et al. (2022) datasets, respectively). We therefore concluded that the reprogramming datasets cannot be used to predict normal aging skin data if we consider age predictions for the reprogramming data to be accurate.\n\nThe dataset of in vivo reprogramming in mouse liver (Chondronasiou et al., 2022), on the other hand, passed the second step of ITTP with remarkable success, demonstrating the performance metrics of Pearson's r = 0.968 and MAE = 2.21 months (Extended Data Figure 3d). Of note, the predictions at step 1 are shifted upward, while the aging trend is still captured well (Pearson's r = 0.826). Finally, applying the ITTP to the datasets of aging mouse blood (Thompson et al., 2018) and mouse embryogenesis (Auclair et al., 2014) resulted in prediction failures similar to that of in vitro reprogramming (Extended Data Figure 3f).\n\nTo summarize, the ITTP method highlights the concerns of applying aging clocks to the reprogramming data (or to any other OOD scenario). As an empirical test to discover possible dataset shift, it helps to assess the risk of prediction failure. The results presented above showed that normal aging cannot be predicted using in vitro reprogramming data, which immediately prompts to inquire whether, in return, the ages across reprogramming can be predicted correctly using data on normal aging.\n\n",
    "RESULTS - Uncertainty‐aware clocks reveal insignificance of age reversal": "In clinical practice, where decision‐making often relies on the level of uncertainty, an ML model is required to estimate not only the desired outcome, but also the uncertainty of its predictions (Chua et al., 2023). A robust model should be able to warn of extreme uncertainty when making predictions on shifted datasets. The majority of aging clock papers, inspired by Horvath (2013) and Hannum et al. (2013), have adopted the ElasticNet model that lacks inherent uncertainty estimation. To address this limitation, we turned to the Gaussian Process Regressor (GPR) model (Wang, 2023; Williams & Rasmussen, 2006), a variant of which was recently employed in aging clocks (Varshavsky et al., 2023) (see Methods).\n\nTo demonstrate the concept of GPR, we trained and tested it on a single CpG site (Figure 5a,b). A Gaussian process (GP) can be viewed as a probability distribution encompassing all possible functions that can be fitted over the training observations (Williams & Rasmussen, 2006). Therefore, for every input methylation value, a fitted GPR model provides an estimation of the most probable age, along with the probability distribution around this estimation with a finite variance that represents a credible interval for the prediction. The credible interval, grounded in Bayesian statistics, is calculated for each individual prediction relying on the training data and prior model assumptions. It should not be confused with a confidence interval which describes only the distribution of multiple predictions.\n\nWhen a GPR fits the training data well, it computes a finite error stemming from the variation of age points associated with any given DNAm value (earlier referred to as aleatoric uncertainty). As methylation values move further away from the training distribution, the model assigns greater epistemic uncertainty. Consequently, the credible interval widens, reflecting that the model is less familiar with this particular range of DNAm values (Figure 5b). The GPR thus provides an estimation of total prediction uncertainty, encompassing both its aleatoric and epistemic components, and presenting it as a credible interval of several standard deviations for every individual prediction. Consequently, these credible intervals are employed to compute significance of difference between two prediction groups, such as control and treatment samples or samples from two different days of reprogramming, using a meta‐regression approach (see Methods). It is important to note that the GPR predictions are influenced by the choice of prior distributions over functions, meaning that the results may vary depending on these underlying assumptions.\n\nIn accordance with the previous sections, we employed GPR models trained on aging datasets to predict rejuvenation trajectories in the respective reprogramming scenarios and to determine the corresponding credible intervals (see Methods). When applied to the in vitro reprogramming dataset (Ohnuki et al., 2014), a skin‐trained GPR (Extended Data Figure 4a) predicted a noticeable epigenetic age decline from reprogramming day 11 through day 28 (Figure 5c), which aligned well with our previous observations obtained with ElasticNet (Figure 3a) and with the observations made by the authors of said dataset. However, the accompanying credible interval of two standard deviations revealed how extremely uncertain the model is about these predictions, especially in the case of the late reprogramming phase. This uncertainty prompts questions regarding the significance of any rejuvenation effect until the 20th day of reprogramming, a point at which a complete erasure of somatic identity was reported in the original study (Ohnuki et al., 2014).\n\nApplying GPR to the in vitro fibroblast reprogramming dataset (Gill et al., 2022) yielded similar results, with two notable differences (Figure 5d). First, the credible interval at reprogramming day 0 is slightly narrower, suggesting that these samples might be more similar to the training set. Second, the model indicated a significant rejuvenation effect between days 0 and 17 (P value = 0.014), indicating that rejuvenation might indeed occur at the later stages of the maturation phase. However, the substantial credible interval at day 17 (spanning from 0 to approximately 70 years) restrains the extent to which confident statements on rejuvenation can be made.\n\nWe next revisited the in vivo mouse reprogramming dataset (Chondronasiou et al., 2022) using the GPR model trained on aging mouse liver (Extended Data Figure 4b) and observed a significant negative rejuvenation effect between the control and OSKM‐treated old mice (Figure 5e). This outcome highlights the importance of incorporating individual prediction uncertainties to resolve differences between groups that are otherwise undistinguishable by simpler methods such as Lasso regression. However, similar to Lasso‐based predictions, we observed a systematic bias in GPR estimations. This bias did not appear to strongly affect credible intervals, which might suggest that GPR underestimates credible intervals in cases of dataset shift, putatively resulting, in this instance, from the comparison of two different mouse strains.\n\nThe GPR model, trained on the mouse blood (Extended Data Figure 4c) and applied to predict the dynamics of epigenetic age during mouse embryogenesis (Auclair et al., 2014), displayed a local minimum at embryonic day 8.5 (Figure 5f), close to the putative ground zero event at E6.5/E7.5 suggested by Kerepesi et al. (2021). However, our GPR predictions are accompanied by large credible intervals, with insignificant age decline between days 3.5 and 8.5 (P value = 0.54) and subsequent insignificant age increase between days 8.5 and 10.5 (P value = 0.37). Consequently, this prevents the definitive designation of day 8.5 as the “ground zero” of epigenetic age. Notably, the credible intervals get narrower throughout the course of embryonic development, supporting our earlier observation of a larger shift between the early days of embryogenesis and the aging process (Extended Data Figure 1j).\n\nOur findings indicate that a GPR model, capable of assessing its prediction uncertainty, can effectively detect covariate shifts in a test dataset by assigning elevated uncertainty to samples not represented in the training data.\n\n",
    "DISCUSSION": "Epigenetic clocks have been widely used to demonstrate age acceleration and deceleration in a variety of research contexts (Yousefi et al., 2022). However, there is still a reluctance to include clock measurements as endpoints in the clinical longevity intervention trials (Justice et al., 2018). In addition to the fact that the existing clocks fail to capture some aging‐associated conditions (Mei et al., 2023), we emphasize that they cannot be easily validated and relied upon, given their inability to estimate prediction uncertainty.\n\nIn this study, we present a computational framework for validating the rejuvenation effects predicted by the epigenetic aging clocks. Due to the unavailability of ground truth values for the biological age, the concept of epigenetic age reversal remains speculative because it cannot be validated directly. Therefore, we have to rely on indirect evidence. To address this challenge, our framework encompasses four specific approaches: covariate shift estimation, comparison of different clock models, the Inverse Train‐Test Procedure (ITTP), and the prediction uncertainty estimation using a Gaussian Process Regression (GPR) model.\n\nAll four approaches were used to explore clock behavior not only in aging, but also in the datasets of cellular reprogramming and embryonic development, because both processes are commonly viewed to be the examples of extensive epigenetic remodeling and putative organismal rejuvenation, as predicted by the clock models trained on aging samples (Kerepesi et al., 2021; Kerepesi & Gladyshev, 2023; Olova et al., 2019; Trapp et al., 2021). Notably, we did not treat these processes as equal, exploring each of them independently. The only claim we investigated was whether they can be reliably evaluated by clock models, regardless of any discrepancies that can be found between their biological mechanisms.\n\nWe demonstrate how the presence of covariate shift can distort model performance using a simple clock model trained and tested on the data of body measurements (weight and height) of individuals with and without achondroplasia. We then show that covariate shift is highly prominent in the DNAm data across cellular reprogramming and embryonic development. Moreover, by applying eight different published aging clocks (Hannum et al., 2013; Horvath, 2013; Horvath et al., 2018; Levine et al., 2018; McEwen et al., 2020; Wu et al., 2019; Zhang et al., 2019) to the in vitro reprogramming data, we illustrate that the magnitude of rejuvenation effect achieved by the end of the maturation phase of reprogramming highly depends on the clock model type and the chosen training data. Across the discussed models, the age reversal effect can differ by up to two orders of magnitude, including null and even negative rejuvenation. Our ITTP approach further reveals that in vitro reprogramming datasets cannot robustly predict normal aging, thus additionally challenging the notion that normal aging can accurately predict reprogramming.\n\nA GPR‐based aging clock can estimate the uncertainty of its own age predictions in the form of standard deviations, even for samples that do not belong to its training distribution. While reproducing the decrease in average epigenetic age, this clock demonstrates no statistically significant difference between the days 0 and 15 of in vitro reprogramming in one dataset (Ohnuki et al., 2014) (Figure 5c), and marginal significance between days 0 and 17 in another dataset (Gill et al., 2022) (Figure 5d). However, the accompanying credible interval at day 17 spans approximately 70 years, thereby preventing definitive conclusions regarding the observed rejuvenation effects.\n\nThe in vivo mouse liver reprogramming data (Chondronasiou et al., 2022) exhibits a covariate distribution closer to that of normal mouse aging. Moreover, it passes the ITTP test, suggesting that in vivo reprogramming might preserve organismal states better than the in vitro procedure. However, we show that both the Lasso and the GPR clock models surprisingly predict old reprogrammed samples to be either of the same age or even significantly older than the old controls (Figure 5e). This finding prompts further forays into the nature of processes accompanying in vivo reprogramming, especially in light of a recent study describing impaired liver function and premature death in mice with continued OSKM induction (Parras et al., 2023).\n\nWhile testing the “ground zero” hypothesis of epigenetic aging (Gladyshev, 2021), we discover significant covariate shift and ITTP failure for the dataset spanning from early to middle embryonic development (Auclair et al., 2014). While average GPR‐predicted ages recapitulate previously described dynamics of epigenetic age decrease in embryogenesis (Kerepesi et al., 2021) and yield age zero at embryonic day 8.5, these dynamics are found to be statistically insignificant from the epistemic uncertainty standpoint (Figure 5f).\n\nWe hypothesize that the GPR model assigns such wide credible intervals to both in vitro reprogramming and embryogenesis because the totipotent and pluripotent states are too unfamiliar to a model trained purely on differentiated somatic cells. Thus, we have shown that an aging clock model that performs well within aging datasets will likely fail to reliably predict rejuvenation events not represented in the training data. To decrease this uncertainty, the inclusion of progenitor cells in the training dataset could prove beneficial. However, this hypothetical procedure requires thorough investigation, and it might still fail to aid in resolving reprogramming‐induced rejuvenation with existing clock models.\n\nOur work should not be viewed as an attempt to prove or disprove the existence of rejuvenation effects, including the “ground zero” hypothesis of epigenetic aging. We also do not aim to comprehensively cover all available datasets of putative rejuvenation, be it reprogramming, embryogenesis, or other interventions. Instead, by concentrating on the most striking examples, we illustrate that the existing aging clocks that rely on overly optimistic assumptions (Sluiskes et al., 2024) cannot serve as reliable biomarkers of rejuvenation.\n\nFrom the ML viewpoint, the effect of OOD samples on the prediction outcome is well‐known (Gawlikowski et al., 2023; Yang et al., 2021), as a trained model is highly unlikely to perform robustly on data out of the original distribution (Gawlikowski et al., 2023; Shvetsova et al., 2021). Likewise, the good performance on the training and the validation datasets cannot guarantee that the model trained to predict normal aging will reliably predict the rejuvenation effects. Nor could it be used as the reprogramming validation method, especially given the lack of ground truth and the large resulting uncertainty. Yet, these approaches appear to have become common today, which is one practice that we hope will be reconsidered.\n\nWhen discussing the reliability of aging clocks, the question of their biological relevance inevitably arises. Recent discussions on the stochastic nature of methylation sites (Meyer & Schumacher, 2024; Tarkhov et al., 2024; Tong et al., 2024), as well as between aging clocks trained on purely stochastic or biologically relevant processes, while seemingly relevant, focus on the biological aspect rather than the purely statistical one addressed in our work. Thus, our framework does not distinguish between stochastic and deterministic CpGs, nor between clocks trained on stochastic versus biologically relevant processes. However, understanding the physical dynamics of DNAm would enable the development of advanced age estimation algorithms, including improved uncertainty models. This promising direction requires thorough future research.\n\nDespite the clock drawbacks, a reliable surrogate health measure (Schork et al., 2022) is still required for the evaluation of longevity drugs and other interventions in clinical trials (Melton, 2023). Several criteria have been proposed for the potential biomarkers of aging (Moqri et al., 2023). We suggest that, in order to gain a wider acceptance within the longevity community, the single‐point age clock predictions must be accompanied by the uncertainty estimation (Chua et al., 2023), while acknowledging for the potential limitations of this estimation. Furthermore, we recommend assessing potential covariate shifts between datasets with methods discussed in this work before applying any aging clock models.\n\nWe advocate for the development of a clinically relevant and reliable aging clock with a clearly defined training target, such as mortality, combined with the ability to estimate prediction uncertainties. This approach is essential for alerting researchers to possible misinterpretations of the trial results. While such a protocol may add complexity to aging clock development, it is crucial for advancing the field and for positioning aging clocks as accurate health estimators.\n\n",
    "METHODS - Height and weight data processing": "For our toy example of the dataset shift, we sourced data from the WHO (World Health Organization, 2006) for the control cohort and from Hoover et al. (Hoover‐Fong et al., 2021) for the achondroplasia cohort. The datasets included height and weight means and standard deviations across various ages: 60–228 months for the control and 0–240 + months for the achondroplasia cohort. We interpolated the control dataset using the methodology by Andres et al. (Andres et al., 2015) to align age ranges (0–240+ months). Assuming a normal joint distribution for height and weight (Hunter et al., 1996), we sampled points with the corresponding means and covariance matrices. Age was uniformly sampled from 0 to 276 months. Thousand samples were generated for each cohort.\n\nUsing 1000 samples from the control cohort, we constructed a bivariate linear regression model with the Python scikit‐learn (Pedregosa et al., 2011) package. Post‐training, this model was used for age prediction in the achondroplasia cohort.\n\n",
    "METHODS - DNAm data processing": "For in vitro reprogramming, we employed two datasets of DNAm profiling throughout the human fibroblast reprogramming timeline by Ohnuki et al. (2014) and Gill et al. (2022), which are the only existing open access DNAm datasets of this kind, and compared them with the aging human skin datasets by Roos et al. (2017) and Vandiver et al. (2015). To compare mouse DNAm profiles across aging, in vivo reprogramming, and embryogenesis using as wide genomic CpG coverage as currently possible, we focused on the methylation data obtained by reduced representation bisulfite sequencing (RRBS) (Li & Tollefsbol, 2021). Thus, we employed multi‐tissue datasets of mouse aging from Thompson et al. (2018) and Meer et al. (2018), the in vivo reprogramming data from Chondronasiou et al. (2022), and the mouse embryogenesis DNAm dataset by Auclair et al. (2014) which stands out as one of the few bulk‐tissue DNAm datasets featuring both early and middle embryonic stages.\n\nFor the studies of Roos et al. (2017) (GSE90124), Vandiver et al. (2015) (GSE51954), Ohnuki et al. (2014) (GSE54848), Gill et al. (2022) (GSE165179), Auclair et al. (2014) (GSE60334), and Chondronasiou et al. (2022) (GSE156557), files containing processed methylation beta values were downloaded from the GEO database under the corresponding accession numbers. For detailed description of sample groups isolated for our analysis, see Table S1. Methylation matrices were assembled for each dataset by merging selected samples and retaining only those CpGs that appeared in every sample of the respective dataset.\n\nTo showcase the absence of covariate shift within the same dataset, we split the dataset from Roos et al. into training and testing subsets. We used the train_test_split function from the Python scikit‐learn library, which ensures that the data is randomly divided into the specified proportions. Specifically, we fixed the random_state parameter for splitting reproducibility, set aside 50% of data for testing and used the remaining 50% for training. This method allows for a randomized and balanced division of the dataset, preventing any biases that might arise from manual or nonrandom splitting procedures.\n\nA processed multi‐tissue RRBS dataset from the Thompson et al. study was downloaded from the GEO database, where it is deposited under accession no. GSE120132 (Thompson et al., 2018). As all other mouse DNAm studies referenced in this study used wild‐type C57Bl/6J or related mouse strains, we selected 196 samples representing this strain from the 549 samples comprising the original dataset. In the original dataset, CpG methylation values from both DNA strands were combined and assigned to the forward strand cytosines, while retaining strand annotation. To utilize as much information as possible, we treated methylation values from forward and backward strands separately. A processed multi‐tissue RRBS dataset from the Meer et al. study comprising 81 samples was also downloaded from the GEO database under accession no. GSE121141 (Meer et al., 2018).\n\nFor the studies of Thompson et al. and Meer et al., we followed the instructions on data processing provided by Trapp et al.: in each dataset, we retained only autosomal DNAm sites that featured at least 5‐fold coverage in no less than 90% of samples, which yielded 1,242,194 and 2,131,404 sites, respectively. For the analysis of embryonic development, we further isolated 50 blood samples from the Thompson et al. dataset. For the analysis of in vivo liver reprogramming, we isolated 30 and 20 liver samples from the Thompson et al. and the Meer et al. datasets, respectively, and merged them into one methylation matrix.\n\n",
    "METHODS - Principles of CpG selection": "CpG site selection for aging clock training is a nuanced challenge, with various authors suggesting distinct, minimally overlapping subsets (Galkin et al., 2020). To tackle this problem, we used CpGs from established clocks most relevant to each corresponding dataset pair, considering tissue composition of the respective datasets. For instance, in analyzing covariate shift between the aging human skin and in vitro human fibroblast reprogramming datasets, Horvath's skin clocks (Horvath et al., 2018) and the corresponding CpGs were employed. While any accurate age‐predicting CpG subset could suffice, we predominantly used known subsets for methodological simplicity where possible. The detailed description of dataset pairs, clock models, and the amount of clock sites observed in the datasets is specified in Table S2.\n\n",
    "METHODS - Principal component analysis (PCA) for covariate shift visualization": "PCA presented in Figure 2c,f,i and Extended Data Figure 1a,d,g,j was conducted on merged dataset pairs to select CpGs for the covariate shift analysis (refer to previous sections). This analysis employed the Python scikit‐learn library (Pedregosa et al., 2011) with the default parameters. The two‐dimensional kernel density estimations of PCA results were performed using the kdeplot function from the Python seaborn package.\n\n",
    "METHODS - Kolmogorov–Smirnov test for a shift of individual covariates": "We employed a two‐tailed Kolmogorov–Smirnov (KS) test on the selected CpGs (refer to site selection principles above) to detect covariate shifts between the dataset pairs. This test assessed the null hypothesis that the beta value distributions for a specific CpG site are identical across a given dataset pair. We applied the Benjamini‐Hochberg correction to the computed p values, considering the adjusted p value below 0.01 as indicative of a significant distributional shift. The KS statistics and the p values were calculated using scipy (Virtanen et al., 2020), and the multiple testing correction was performed with statsmodels (Seabold & Perktold, 2010) in Python.\n\nImportantly, the KS test can be sensitive to small sample sizes. With small datasets, the test may not have enough power to detect meaningful differences between distributions that may potentially lead to type II statistical error. This is why it is better to consider results of this test along with PCA projections to detect covariate shift. Another potential limitation of KS test is a sensitivity to outliers, given that the number of present outliers is high. We do not, however, expect the number of outliers in the compared datasets to be high compared to the sample size. Another possible limitation of using the KS test in the context of covariate shift detection arises when the training dataset is a generalization of the test dataset. In other words, the samples in the test dataset are represented in the training dataset, but not all samples in the training dataset are represented in the test dataset.\n\n",
    "METHODS - Testing in vitro reprogramming datasets with different published epigenetic aging clocks": "We evaluated the consistency of predictions across eight aging clock models using the R methylclock (Pelegí‐Sisó et al., 2021) package, which predicts epigenetic age from the input matrices of CpG methylation beta values. The clocks included: Horvath's multi‐tissue clock (Horvath, 2013), Hannum's blood clock (Hannum et al., 2013), Horvath's skin+blood clock (Horvath et al., 2018) (notated as Horvath skin in this paper), PedBE clock (McEwen et al., 2020), Wu's clock (Wu et al., 2019), Zhang's Best Linear Unbiased Prediction (BLUP) and ElasticNet‐based (notated as Zhang in this paper) clocks (Zhang et al., 2019), and Levine's blood clock (also known as PhenoAge) (Levine et al., 2018). All methylclock‐generated predictions are available in our GitHub repository provided further below.\n\n",
    "METHODS - Testing in vitro reprogramming datasets with different models of aging clocks trained on the same dataset": "To evaluate prediction consistency across different aging clock model families, we employed five different ML models from the scikit‐learn package: k‐neighbors regressor (the KNeighborsRegressor function), random forest regressor (the RandomForestRegressor function), support vector regressor (the SVR function), Bayesian ridge regressor (the BayesianRidge function), and histogram‐based gradient boosting regressor (the HistGradientBoostingRegressor function). These models were trained on the aging human skin dataset (Roos et al., 2017) using 5‐fold cross‐validation and hyperparameter optimization via grid search, assessing model performance with the mean squared error metric. Performance metrics of the optimally‐tuned models for both the training and testing subsets are summarized in Table 1.\n\n",
    "METHODS - Lasso clocks for the in vivo reprogramming testing": "We observed that the in vivo reprogramming dataset (Chondronasiou et al., 2022) exhibited limited overlap with three established mouse aging clocks (7/582 sites in the Thompson clocks (Thompson et al., 2018), 3/90 sites in the Meer clocks (Meer et al., 2018), and 16/436 sites in the Petkovich clocks (Petkovich et al., 2017)), potentially impairing clock predictions. Consequently, we developed a new clock using a Lasso penalized regression model, trained on the liver samples combined from the Thompson et al. (Thompson et al., 2018) and Meer et al. (Meer et al., 2018) aging mouse liver datasets. Utilizing the LassoCV class from scikit‐learn (Pedregosa et al., 2011), we identified the optimal regularization hyperparameter α through 5‐fold cross‐validation. The final model, selecting 22 out of 16,849 CpGs (Table S3), exhibited strong performance while testing (MAE = 2.2 months, R\n2 = 0.866), as detailed in Figure 3e. This model was then applied to predict epigenetic age in the in vivo reprogramming dataset (Chondronasiou et al., 2022).\n\n",
    "METHODS - Inverse train‐test procedure with Lasso regression": "In general, the Inverse Train‐Test procedure (ITTP) can be applied to any pair of datasets to test their interchangeability. However, in practice, the outcome of the procedure will depend on the generalizing abilities of the chosen model. Thus, it is crucial to use models from the same family (for instance, linear models) at steps 1 and 2 of the ITTP. We decided to choose a linear regression model with Lasso penalization as a base model (i.e., model 1 and model 2 in Figure 4a) for the ITTP because it has generalization properties equivalent to ElasticNet (most often used aging clock model), but is easier to train (optimizing one hyperparameter instead of two). Below, we provide a detailed algorithm for the ITTP procedure for both use cases discussed in this study, presuming that the Lasso model is used as the base model.\n\n",
    "METHODS - Prediction uncertainty inference using GPR model": "A GPR model was developed to predict the age of samples given their methylome. GPR is a flexible nonparametric Bayesian approach to the regression tasks (Williams & Rasmussen, 2006). In our model, the inputs are the same CpGs used for covariate shift analysis from the published and the newly constructed (see the section about Lasso training) aging clocks (Table S2), and the outputs are the ages of the sample donors. The model was trained using the Python scikit‐learn package with a composite kernel comprising the Radial Basis Function (RBF) and the white noise kernels elaborated further below.\n\nGiven that the methodology we use to build the GPR‐based aging clocks has been described in detail elsewhere (Varshavsky et al., 2023), this section is focused primarily on deriving the prediction uncertainty, which is essential for our study. A Gaussian Process (GP) is a probability distribution over possible functions that fit a set of points. Formally, it is a collection of random variables, any finite number of which have a joint Gaussian distribution (Williams & Rasmussen, 2006). Given a train sample set X = {x\n1…, x\n\nn\n} ∈ Rd, a mean function m: Rd → R, and a covariance function k: Rd × Rd → R, a GP can be written as f(x) ∼ GP(m(x), k(x, x\n')), if the outputs f = (f(x\n1), f(x\n\nn\n))\nT\n have a Gaussian distribution described by f ∼ N(μ, Σ), where μ = m(x\n1…, x\n\nn\n) and Σ\ni,j\n = k(x\n\ni\n, x\n\nj\n). The mean function is usually assumed to be the zero function, and the covariance function is a kernel function chosen based on assumptions about the function to be modeled. We tried different kernel functions and found that the sum of the Radial Basis Function and the white noise kernels performed the best in terms of prediction metrics (MAE and R\n2). The RBF kernel was also used by the authors of the previously reported GPR‐based aging clock (Varshavsky et al., 2023). The RBF kernel is defined as:(1)kxixj=s2exp−xi−xj22l2,where s\n2 is the variance hyperparameter and l is the length‐scale hyperparameter to control the smoothness of the modeled function, or the speed of its variation. Because GP assumes the output variable includes an additive Gaussian noise part ε ∼ N (0, σ\n2), that is, y\n\ni\n = f (x\n\ni\n) + ε, the vector of outputs is viewed as y ∼ N (0, Σ + σ\n2\nI). The term σ\n2\nI reflects the white noise kernel added to the model to account for the noise in observations, which corresponds to the aleatoric part of the prediction uncertainty.\n\nGiven a test point x*, its output distribution is defined as f*|x*, X, y which is a conditional Gaussian distribution of the following form:(2)f*∣x*,X,y∼Nμ*,σ*2=Nk*TΣ+σ2I−1y, kx*,x*−k*TΣ+σ2I−1k*where k* = (k (x\n1, x*)…, k (x\n\nn\n, x*))\nT\n.\n\nThus, given the training data, the distribution of predictions of a new point is given by a closed analytical form of Gaussian distribution. In our model, the inputs are the CpG methylation vectors, and the outputs are the chronological ages. The mean of the distribution μ* can be used as the final prediction of the regression model (corresponds to the prediction of ElasticNet or other models). At the same time, the variance of the distribution (σ*)2 expresses the level of total prediction uncertainty—one of the most important aspects of our study. One can see that the magnitude of the uncertainty depends on the vector of covariates k\n* of the new sample x\n* with the training set samples X. Because the RBF kernel relies on the quadratic distance between the samples, the total prediction uncertainty for an OOD sample will increase as the sample moves away from the training distribution until it reaches the limiting value (σ*)2 ≈ k(x*, x*) = s\n2, determining the upper bound of the prediction uncertainty the model can estimate for an OOD sample.\n\nAlthough the chosen RBF kernel allows us to obtain the best performance metrics on the validation subset, it is worth noting that it also determines the nature and the rate of increase in uncertainty as the test point moves away from the training set. This is an important assumption of the model, which may lead to both an underestimation of uncertainty in the vicinity of the training dataset and an increase in uncertainty in a far distance from it.\n\n",
    "METHODS - Testing the rejuvenation effects using a meta‐regression approach": "The Gaussian process model, yielding uncertainty levels for individual sample predictions as Gaussian distribution variances, enables statistical comparison of two predictions via, for example, the z‐test (if two variances are assumed to be equal). For comparing prediction groups, each with unique variances, we employed advanced meta‐analysis techniques. Utilizing the meta_regression function from Python PyMARE 0.0.3 (Yarkoni et al., 2022), we accounted for individual age prediction variances in two in vitro reprogramming groups (e.g., days 0 and 15). This function, which incorporates average ages, variances, and a binary group indicator in the design matrix, uses a restricted maximum likelihood approach to optimize meta‐regression coefficients, providing coefficient estimates and their P values.\n\n",
    "METHODS - Computational and statistical analyses": "Except for the methylclock 0.7.8 predictions conducted via R 4.2, all other analyses were performed in Python 3.9.18 using numpy 1.22.4, pandas 1.5.1, scipy 1.7.2, and scikit‐learn 1.2.1 for data handling and the majority of calculations, and matplotlib 3.5.1 in combination with seaborn 0.11.2 for data visualization. Multiple testing corrections were performed with statsmodels 0.13.2 where indicated. Other packages and functions used for specific computational and statistical analyses are cited in the corresponding sections above.\n\n",
    "AUTHOR CONTRIBUTIONS": "DK and EK conceived the study. DK wrote the code for an essential part of data analysis and prepared the initial version of the figures. EK prepared the final version of all figures and contributed to the human weight‐height data analysis. EE prepared DNA methylation datasets and substantially elaborated on the manuscript. DK, EK, and EE prepared the initial version of the manuscript. EEK and DVD supervised the study. All authors contributed to the final version of the article.\n\n",
    "FUNDING INFORMATION": "This work was supported by program “Skolkovo Institute of Science and Technology – University of Sharjah Joint Projects: Artificial Intelligence for Life”.\n\n",
    "CONFLICT OF INTEREST STATEMENT": "The authors declare no competing interests.\n\n"
  },
  "mesh_terms": [
    "Rejuvenation",
    "Uncertainty",
    "Aging",
    "Humans",
    "Animals",
    "Cellular Reprogramming",
    "Epigenesis, Genetic",
    "Cellular Senescence",
    "Mice",
    "DNA Methylation",
    "Biological Clocks",
    "Reproducibility of Results"
  ],
  "keywords": [
    "DNA methylation",
    "cell reprogramming",
    "dataset shift",
    "epigenetic aging clocks",
    "epistemic uncertainty",
    "rejuvenation"
  ],
  "citation_count": 9,
  "authors": [
    {
      "name": "Dmitrii Kriukov",
      "affiliations": [
        "Skolkovo Institute of Science and Technology  Moscow Russia",
        "Artificial Intelligence Research Institute  Moscow Russia"
      ]
    },
    {
      "name": "Ekaterina Kuzmina",
      "affiliations": [
        "Skolkovo Institute of Science and Technology  Moscow Russia",
        "Artificial Intelligence Research Institute  Moscow Russia"
      ]
    },
    {
      "name": "Evgeniy Efimov",
      "affiliations": [
        "Skolkovo Institute of Science and Technology  Moscow Russia"
      ]
    },
    {
      "name": "Dmitry V. Dylov",
      "affiliations": [
        "Skolkovo Institute of Science and Technology  Moscow Russia",
        "Artificial Intelligence Research Institute  Moscow Russia"
      ]
    },
    {
      "name": "Ekaterina E. Khrameeva",
      "affiliations": [
        "Skolkovo Institute of Science and Technology  Moscow Russia"
      ]
    }
  ],
  "year": 2024,
  "journal": "Aging Cell",
  "pmid": "39072888",
  "pmcid": "PMC11561706",
  "collection_date": "2025-10-11",
  "is_negative_example": true
}